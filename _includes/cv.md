## <i class="fa fa-chevron-right"></i> Bio

<p style="text-align: justify;">
    Renan Francisco Santos Souza holds a Ph.D. (2019) and an M.Sc. (2015) in Computer Science from [COPPE/Federal University of Rio de Janeiro](https://www.cos.ufrj.br) (UFRJ), and a [B.Sc. in Computer Science](https://dcc.ufrj.br) from UFRJ (2009-2013). Since 2015, he works at [IBM Research Brazil](https://www.research.ibm.com/labs/brazil/), where he is a Research Scientist in the [Industrial Cloud Technologies](https://researcher.watson.ibm.com/researcher/view_group_pubs.php?grp=5113) group. He has been working both as a software engineer and a researcher in several projects since 2010 and has been actively publishing scientific papers in refereed international conferences and journals since 2014. During his B.Sc., he spent a school year at the computer science department at [Missouri State University](https://www.missouristate.edu/) and did a summer internship at [Stanford University](https://www.stanford.edu/) in the [SLAC](https://www6.slac.stanford.edu/) National Laboratory. During his Ph.D., he was a visiting researcher with the [Scientific Data Management](https://team.inria.fr/zenith/) team at [Inria/Univ. Montpellier](https://inria.fr/) in France in 2019. In 2017, he won the best M.Sc. thesis award from SBBD, the main conference on data management in Latin America. He researches large-scale data science and engineering techniques for the support of Artificial Intelligence systems.
</p>


See 
<a href="/cv" target='_blank' class="fa fa-download">
    Full CV
</a>
for complete information about education, professional experience, and technical skills.


## <i class="fa fa-chevron-right"></i> Research Interests

<p style="text-align: justfy">
        Large-scale Data Science and Engineering &bull;
        Parallel Workflows &bull;
        Data Provenance &bull;
        Big Data Analytics &bull;
        High Performance Computing in Clusters and Clouds &bull;
        Machine Learning &bull;
</p>


<h2><i class="fa fa-chevron-right"></i> Selected Publications <a href="/publications">
<br/>
<span style="font-size: 60%"><strong>All publications</strong></span><img src="/images/external-link.png" style="border: 0; width: 0.7em;" /></a></h2>




<table class="table table-hover">

<tr>
<td class="col-md-3 hidden-xs hidden-sm" style="vertical-align: middle;"><a href='https://doi.org/10.1109/WORKS49585.2019.00006' target='_blank'><img src="images/publications/souza_provenancedata_2019.png" style="border:0"/></a> </td>
<td style="vertical-align: middle; text-align: justify;">
    
            <strong>Provenance Data in the Machine Learning Lifecycle in Computational Science and Engineering</strong><br>
            <strong>R. Souza</strong>, L. Azevedo, V. Lourenço, E. Soares, R. Thiago, R. Brandão, D. Civitarese, E. Vital Brazil, M. Moreno, P. Valduriez, M. Mattoso, R. Cerqueira, and M. A. S. Netto<br><i>Workflows in Support of Large-Scale Science (WORKS) co-located with the ACM/IEEE International Conference for High Performance Computing, Networking, Storage, and Analysis (SC)</i>, 2019.<br>
            
            [1] 
[<a href='javascript: none'
    onclick='$("#abs_souza_provenancedata_2019").toggle()'>abstract</a>] [<a href='https://doi.org/10.1109/WORKS49585.2019.00006' target='_blank'>doi</a>]  [<a href='https://arxiv.org/pdf/1910.04223' target='_blank'>pdf</a>]  
            [<a href='javascript: none'
            onclick='$("#bib_souza_provenancedata_2019").toggle()'>bibtex</a>]<br>
            
<div id="abs_souza_provenancedata_2019" style="text-align: justify; display: none" markdown="1">
<strong>Abstract. </strong>Machine Learning (ML) has become essential in several industries. In Computational Science and Engineering (CSE), the complexity of the ML lifecycle comes from the large variety of data, scientists' expertise, tools, and workflows. If data are not tracked properly during the lifecycle, it becomes unfeasible to recreate a ML model from scratch or to explain to stakeholders how it was created. The main limitation of provenance tracking solutions is that they cannot cope with provenance capture and integration of domain and ML data processed in the multiple workflows in the lifecycle while keeping the provenance capture overhead low. To handle this problem, in this paper we contribute with a detailed characterization of provenance data in the ML lifecycle in CSE; a new provenance data representation, called PROV-ML, built on top of W3C PROV and ML Schema; and extensions to a system that tracks provenance from multiple workflows to address the characteristics of ML and CSE, and to allow for provenance queries with a standard vocabulary. We show a practical use in a real case in the Oil and Gas industry, along with its evaluation using 48 GPUs in parallel.<br/><strong>Keywords: </strong> Machine Learning Lifecycle, Workflow Provenance, Computational Science and Engineering
</div>

            
<div id="bib_souza_provenancedata_2019" style="display: none; background-color: #eee; font-family:Courier; font-size: 0.8em; text-align: justify; border-color: gray; border: 1px solid lightgray;">
@inproceedings&#123;souza_provenancedata_2019,<br/>&nbsp;&nbsp;abstract = &#123;Machine Learning (ML) has become essential in several industries. In Computational Science and Engineering (CSE), the complexity of the ML lifecycle comes from the large variety of data, scientists' expertise, tools, and workflows. If data are not tracked properly during the lifecycle, it becomes unfeasible to recreate a ML model from scratch or to explain to stakeholders how it was created. The main limitation of provenance tracking solutions is that they cannot cope with provenance capture and integration of domain and ML data processed in the multiple workflows in the lifecycle while keeping the provenance capture overhead low. To handle this problem, in this paper we contribute with a detailed characterization of provenance data in the ML lifecycle in CSE; a new provenance data representation, called PROV-ML, built on top of W3C PROV and ML Schema; and extensions to a system that tracks provenance from multiple workflows to address the characteristics of ML and CSE, and to allow for provenance queries with a standard vocabulary. We show a practical use in a real case in the Oil and Gas industry, along with its evaluation using 48 GPUs in parallel.&#125;,<br/>&nbsp;&nbsp;author = &#123;Souza, Renan and Azevedo, Leonardo and Lourenço, Vítor and Soares, Elton and Thiago, Raphael and Brandão, Rafael and Civitarese, Daniel and Vital Brazil, Emilio and  Moreno, Marcio and  Valduriez, Patrick and  Mattoso, Marta and Cerqueira, Renato and A. S. Netto, Marco&#125;,<br/>&nbsp;&nbsp;booktitle = &#123;Workflows in Support of Large-Scale Science (&#123;WORKS&#125;) co-located with the &#123;ACM&#125;/&#123;IEEE&#125; International Conference for High Performance Computing, Networking, Storage, and Analysis (&#123;SC&#125;)&#125;,<br/>&nbsp;&nbsp;doi = &#123;10.1109/WORKS49585.2019.00006&#125;,<br/>&nbsp;&nbsp;keyword = &#123;Machine Learning Lifecycle, Workflow Provenance, Computational Science and Engineering&#125;,<br/>&nbsp;&nbsp;pages = &#123;1--10&#125;,<br/>&nbsp;&nbsp;pdf = &#123;https://arxiv.org/pdf/1910.04223&#125;,<br/>&nbsp;&nbsp;title = &#123;Provenance Data in the Machine Learning Lifecycle in Computational Science and Engineering&#125;,<br/>&nbsp;&nbsp;year = &#123;2019&#125;<br/>&#125;<br/><br/>
</div>

        
</td>
</tr>


<tr>
<td class="col-md-3 hidden-xs hidden-sm" style="vertical-align: middle;"><a href='https://doi.org/10.1109/eScience.2019.00047' target='_blank'><img src="images/publications/souza_efficient_2019.png" style="border:0"/></a> </td>
<td style="vertical-align: middle; text-align: justify;">
    
            <strong>Efficient Runtime Capture of Multiworkflow Data Using Provenance</strong><br>
            <strong>R. Souza</strong>, L. Azevedo, R. Thiago, E. Soares, M. Nery, M. Netto, E. Brazil, R. Cerqueira, P. Valduriez, and M. Mattoso<br><i>IEEE International Conference on e-Science (eScience)</i>, 2019.<br>
            
            [2] 
[<a href='javascript: none'
    onclick='$("#abs_souza_efficient_2019").toggle()'>abstract</a>] [<a href='https://doi.org/10.1109/eScience.2019.00047' target='_blank'>doi</a>]  [<a href='https://hal-lirmm.ccsd.cnrs.fr/lirmm-02265932/document' target='_blank'>pdf</a>]  
            [<a href='javascript: none'
            onclick='$("#bib_souza_efficient_2019").toggle()'>bibtex</a>]<br>
            
<div id="abs_souza_efficient_2019" style="text-align: justify; display: none" markdown="1">
<strong>Abstract. </strong>Computational  Science  and  Engineering  (CSE) projects are typically developed by multidisciplinary teams. Despite being part of the same project, each team manages its own workflows, using  specific  execution  environments  and  data processingtools. Analyzing the data processed by all workflows globally is a core task in a CSE project. However, this analysis is hard because the data generated by these workflows are not integrated. In addition, since these workflows may take a long time to execute, data analysis needs to be done at runtime to reduce cost and time of the CSE project. A typical solution in scientific data analysis is to capture and relate the data in a provenance database while the workflows run, thus allowing for data analysisat runtime. However, the main problem is that such data capture competes with the running workflows, adding significant overhead to their execution. To mitigate this problem, we introduce in this paper a system called ProvLake, which adopts design principles for providing efficientdistributed data capture from the workflows. While capturing the data, ProvLake logically integrates and ingests them into a provenance database ready for analyses at runtime. We validated  ProvLake ina  real  use  case  in  the  O&G  industry encompassing four workflows that process 5TB datasets for a deep learning classifier. Compared with Komadu, the closest solution that meets our goals, our approach enables runtime multiworkflow data analysis with much smaller overhead, such as 0.1%.<br/><strong>Keywords: </strong> Multiworkflow provenance, Multi-Data Lineage, Data Lake Provenance, ProvLake
</div>

            
<div id="bib_souza_efficient_2019" style="display: none; background-color: #eee; font-family:Courier; font-size: 0.8em; text-align: justify; border-color: gray; border: 1px solid lightgray;">
@inproceedings&#123;souza_efficient_2019,<br/>&nbsp;&nbsp;abstract = &#123;Computational  Science  and  Engineering  (CSE) projects are typically developed by multidisciplinary teams. Despite being part of the same project, each team manages its own workflows, using  specific  execution  environments  and  data processingtools. Analyzing the data processed by all workflows globally is a core task in a CSE project. However, this analysis is hard because the data generated by these workflows are not integrated. In addition, since these workflows may take a long time to execute, data analysis needs to be done at runtime to reduce cost and time of the CSE project. A typical solution in scientific data analysis is to capture and relate the data in a provenance database while the workflows run, thus allowing for data analysisat runtime. However, the main problem is that such data capture competes with the running workflows, adding significant overhead to their execution. To mitigate this problem, we introduce in this paper a system called ProvLake, which adopts design principles for providing efficientdistributed data capture from the workflows. While capturing the data, ProvLake logically integrates and ingests them into a provenance database ready for analyses at runtime. We validated  ProvLake ina  real  use  case  in  the  O&G  industry encompassing four workflows that process 5TB datasets for a deep learning classifier. Compared with Komadu, the closest solution that meets our goals, our approach enables runtime multiworkflow data analysis with much smaller overhead, such as 0.1\%.&#125;,<br/>&nbsp;&nbsp;author = &#123;Souza, Renan and Azevedo, Leonardo and Thiago, Raphael and Soares, Elton and Nery, Marcelo and Netto, Marco and Brazil, Emilio Vital and Cerqueira, Renato and Valduriez, Patrick and Mattoso, Marta&#125;,<br/>&nbsp;&nbsp;booktitle = &#123;&#123;IEEE&#125; International Conference on e-Science (eScience)&#125;,<br/>&nbsp;&nbsp;doi = &#123;10.1109/eScience.2019.00047&#125;,<br/>&nbsp;&nbsp;keyword = &#123;Multiworkflow provenance, Multi-Data Lineage, Data Lake Provenance, ProvLake&#125;,<br/>&nbsp;&nbsp;pages = &#123;1--10&#125;,<br/>&nbsp;&nbsp;pdf = &#123;https://hal-lirmm.ccsd.cnrs.fr/lirmm-02265932/document&#125;,<br/>&nbsp;&nbsp;title = &#123;Efficient Runtime Capture of Multiworkflow Data Using Provenance&#125;,<br/>&nbsp;&nbsp;year = &#123;2019&#125;<br/>&#125;<br/><br/>
</div>

        
</td>
</tr>


<tr>
<td class="col-md-3 hidden-xs hidden-sm" style="vertical-align: middle;"><a href='https://doi.org/10.1016/j.future.2019.05.011' target='_blank'><img src="images/publications/souza_keeping_2019.png" style="border:0"/></a> </td>
<td style="vertical-align: middle; text-align: justify;">
    
            <strong>Keeping Track of User Steering Actions in Dynamic Workflows</strong><br>
            <strong>R. Souza</strong>, V. Silva, J. Camata, A. Coutinho, P. Valduriez, and M. Mattoso<br><i>Future Generation Computer Systems</i>, 2019.<br>
            
            [3] 
[<a href='javascript: none'
    onclick='$("#abs_souza_keeping_2019").toggle()'>abstract</a>] [<a href='https://doi.org/10.1016/j.future.2019.05.011' target='_blank'>doi</a>]  [<a href='https://hal-lirmm.ccsd.cnrs.fr/lirmm-02127456/document' target='_blank'>pdf</a>]  
            [<a href='javascript: none'
            onclick='$("#bib_souza_keeping_2019").toggle()'>bibtex</a>]<br>
            
<div id="abs_souza_keeping_2019" style="text-align: justify; display: none" markdown="1">
<strong>Abstract. </strong>In long-lasting scientific workflow executions in HPC machines, computational scientists (the users in this work) often need to fine-tune several workflow parameters. These tunings are done through user steering actions that may significantly improve performance (e.g., reduce execution time) or improve the overall results. However, in executions that last for weeks, users can lose track of what has been adapted if the tunings are not properly registered. In this work, we build on provenance data management to address the problem of tracking online parameter fine-tuning in dynamic workflows steered by users. We propose a lightweight solution to capture and manage provenance of the steering actions online with negligible overhead. The resulting provenance database relates tuning data with data for domain, dataflow provenance, execution, and performance, and is available for analysis at runtime. We show how users may get a detailed view of the execution, providing insights to determine when and how to tune. We discuss the applicability of our solution in different domains and validate its ability to allow for online capture and analyses of parameter fine-tunings in a real workflow in the Oil and Gas industry. In this experiment, the user could determine which tuned parameters influenced simulation accuracy and performance. The observed overhead for keeping track of user steering actions at runtime is less than 1% of total execution time.<br/><strong>Keywords: </strong> Dynamic workflows, Computational steering, Provenance data, Parameter tuning
</div>

            
<div id="bib_souza_keeping_2019" style="display: none; background-color: #eee; font-family:Courier; font-size: 0.8em; text-align: justify; border-color: gray; border: 1px solid lightgray;">
@article&#123;souza_keeping_2019,<br/>&nbsp;&nbsp;abstract = &#123;In long-lasting scientific workflow executions in HPC machines, computational scientists (the users in this work) often need to fine-tune several workflow parameters. These tunings are done through user steering actions that may significantly improve performance (e.g., reduce execution time) or improve the overall results. However, in executions that last for weeks, users can lose track of what has been adapted if the tunings are not properly registered. In this work, we build on provenance data management to address the problem of tracking online parameter fine-tuning in dynamic workflows steered by users. We propose a lightweight solution to capture and manage provenance of the steering actions online with negligible overhead. The resulting provenance database relates tuning data with data for domain, dataflow provenance, execution, and performance, and is available for analysis at runtime. We show how users may get a detailed view of the execution, providing insights to determine when and how to tune. We discuss the applicability of our solution in different domains and validate its ability to allow for online capture and analyses of parameter fine-tunings in a real workflow in the Oil and Gas industry. In this experiment, the user could determine which tuned parameters influenced simulation accuracy and performance. The observed overhead for keeping track of user steering actions at runtime is less than 1\% of total execution time.&#125;,<br/>&nbsp;&nbsp;author = &#123;Souza, Renan and Silva, Vítor and Camata, Jose J. and Coutinho, Alvaro L. G. A. and Valduriez, Patrick and Mattoso, Marta&#125;,<br/>&nbsp;&nbsp;doi = &#123;10.1016/j.future.2019.05.011&#125;,<br/>&nbsp;&nbsp;issn = &#123;0167-739X&#125;,<br/>&nbsp;&nbsp;journal = &#123;Future Generation Computer Systems&#125;,<br/>&nbsp;&nbsp;keyword = &#123;Dynamic workflows, Computational steering, Provenance data, Parameter tuning&#125;,<br/>&nbsp;&nbsp;pages = &#123;624--643&#125;,<br/>&nbsp;&nbsp;pdf = &#123;https://hal-lirmm.ccsd.cnrs.fr/lirmm-02127456/document&#125;,<br/>&nbsp;&nbsp;title = &#123;Keeping Track of User Steering Actions in Dynamic Workflows&#125;,<br/>&nbsp;&nbsp;volume = &#123;99&#125;,<br/>&nbsp;&nbsp;year = &#123;2019&#125;<br/>&#125;<br/><br/>
</div>

        
</td>
</tr>


<tr>
<td class="col-md-3 hidden-xs hidden-sm" style="vertical-align: middle;"><a href='https://doi.org/10.1016/j.future.2017.11.028' target='_blank'><img src="images/publications/Souza2017Data.png" style="border:0"/></a> </td>
<td style="vertical-align: middle; text-align: justify;">
    
            <strong>Data Reduction in Scientific Workflows Using Provenance Monitoring and User Steering</strong><br>
            <strong>R. Souza</strong>, V. Silva, A. Coutinho, P. Valduriez, and M. Mattoso<br><i>Future Generation Computer Systems</i>, 2017.<br>
            
            [4] 
[<a href='javascript: none'
    onclick='$("#abs_Souza2017Data").toggle()'>abstract</a>] [<a href='https://doi.org/10.1016/j.future.2017.11.028' target='_blank'>doi</a>]  [<a href='https://hal-lirmm.ccsd.cnrs.fr/lirmm-01679967/document' target='_blank'>pdf</a>]  
            [<a href='javascript: none'
            onclick='$("#bib_Souza2017Data").toggle()'>bibtex</a>]<br>
            
<div id="abs_Souza2017Data" style="text-align: justify; display: none" markdown="1">
<strong>Abstract. </strong>Scientific workflows need to be iteratively, and often interactively, executed for large input datasets. Reducing data from input datasets is a powerful way to reduce overall execution time in such workflows. When this is accomplished online (i.e., without requiring the user to stop execution to reduce the data, and then resume), it can save much time. However, determining which subsets of the input data should be removed becomes a major problem. A related problem is to guarantee that the workflow system will maintain execution and data consistent with the reduction. Keeping track of how users interact with the workflow is essential for data provenance purposes. In this paper, we adopt the “human-in-the-loop” approach, which enables users to steer the running workflow and reduce subsets from datasets online. We propose an adaptive workflow monitoring approach that combines provenance data monitoring and computational steering to support users in analyzing the evolution of key parameters and determining the subset of data to remove. We extend a provenance data model to keep track of users’ interactions when they reduce data at runtime. In our experimental validation, we develop a test case from the oil and gas domain, using a 936-cores cluster. The results on this test case show that the approach yields reductions of 32% of execution time and 14% of the data processed.<br/><strong>Keywords: </strong> Scientific Workflows, Human in the Loop, Online Data Reduction, Provenance Data, Dynamic Workflows
</div>

            
<div id="bib_Souza2017Data" style="display: none; background-color: #eee; font-family:Courier; font-size: 0.8em; text-align: justify; border-color: gray; border: 1px solid lightgray;">
@article&#123;Souza2017Data,<br/>&nbsp;&nbsp;abstract = &#123;Scientific workflows need to be iteratively, and often interactively, executed for large input datasets. Reducing data from input datasets is a powerful way to reduce overall execution time in such workflows. When this is accomplished online (i.e., without requiring the user to stop execution to reduce the data, and then resume), it can save much time. However, determining which subsets of the input data should be removed becomes a major problem. A related problem is to guarantee that the workflow system will maintain execution and data consistent with the reduction. Keeping track of how users interact with the workflow is essential for data provenance purposes. In this paper, we adopt the “human-in-the-loop” approach, which enables users to steer the running workflow and reduce subsets from datasets online. We propose an adaptive workflow monitoring approach that combines provenance data monitoring and computational steering to support users in analyzing the evolution of key parameters and determining the subset of data to remove. We extend a provenance data model to keep track of users’ interactions when they reduce data at runtime. In our experimental validation, we develop a test case from the oil and gas domain, using a 936-cores cluster. The results on this test case show that the approach yields reductions of 32\% of execution time and 14\% of the data processed.&#125;,<br/>&nbsp;&nbsp;author = &#123;Souza, Renan and Silva, Vítor and Coutinho, Alvaro L. G. A. and Valduriez, Patrick and Mattoso, Marta&#125;,<br/>&nbsp;&nbsp;doi = &#123;10.1016/j.future.2017.11.028&#125;,<br/>&nbsp;&nbsp;issn = &#123;0167-739X&#125;,<br/>&nbsp;&nbsp;journal = &#123;Future Generation Computer Systems&#125;,<br/>&nbsp;&nbsp;keyword = &#123;Scientific Workflows, Human in the Loop, Online Data Reduction, Provenance Data, Dynamic Workflows&#125;,<br/>&nbsp;&nbsp;pages = &#123;1--34&#125;,<br/>&nbsp;&nbsp;pdf = &#123;https://hal-lirmm.ccsd.cnrs.fr/lirmm-01679967/document&#125;,<br/>&nbsp;&nbsp;title = &#123;Data Reduction in Scientific Workflows Using Provenance Monitoring and User Steering&#125;,<br/>&nbsp;&nbsp;volume = &#123;online&#125;,<br/>&nbsp;&nbsp;year = &#123;2017&#125;<br/>&#125;<br/><br/>
</div>

        
</td>
</tr>


</table>
